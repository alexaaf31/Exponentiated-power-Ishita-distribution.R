# Function to calculate information criteria (AIC, BIC, CAIC, HQIC)
criterios <- function(value, num_params, num_data_points) {
  # value - the value from optimization
  # num_params - the number of parameters
  # num_data_points - the number of data points
  
  # Calculate log-likelihood
  l <- 2 * value
  
  # Calculate AIC
  AIC <- l + 2 * num_params
  
  # Calculate BIC
  BIC <- l + num_params * log(num_data_points)
  
  # Calculate CAIC
  CAIC <- AIC + (2 * (num_params + 2) * (num_params + 3)) / (num_data_points - num_params - 3)
  
  # Calculate HQIC
  HQIC <- l + 2 * log(log(num_data_points)) * num_params
  
  # Combine results into a matrix
  result <- cbind(AIC, CAIC, BIC, HQIC)
  
  # Return results
  return(result)
}



# Function to calculate confidence intervals and p-values of parameters
IC <- function(parametros, hessiana, n) {
  # Calculate variance-covariance matrix
  Var <- solve(hessiana, tol = 1e-15)
  
  # Calculate standard errors of parameters
  SE <- sqrt(diag(Var))
  
  # Calculate t-values of parameters
  tvalue <- parametros / SE
  
  # Calculate p-values of parameters
  pvalue <- 2 * pt(abs(tvalue), n, lower.tail = FALSE)
  
  # Calculate confidence intervals of parameters
  LI <- parametros - qt(0.975, n) * SE
  LS <- parametros + qt(0.975, n) * SE
  
  # Combine results into a matrix
  resul <- cbind(parametros, SE, tvalue, pvalue, LI, LS)
  colnames(resul) <- c("Parameter", "SE", "t-value", "p-value", "Lower Bound", "Upper Bound")
  
  # Return results
  return(resul)
}

setwd("D:\\Sync\\Sync\\Doutorado UFPE\\Tese\\tese_escrita_inglês\\EPI\\aplicação\\data")
require(survival)
require(AdequacyModel)

dados = read.table("COVID19 data.txt", header = T)
t = dados$times
hist(t,border = "black",col = "white", xlab = "age ( in years)",main = "")
y=log(t)
censur = dados$censor

# Log-exponentiated power Ishita

EPI<-function(par){
  c     = par[1]
  sigma = par[2]
  b0    = par[3]
  b1    = par[4]
  b2    = par[5]
  if(any(sigma < 1e-20)) return(.Machine$double.xmax^.5)
  mu=b0 + b1*dados$age + b2*dados$diab
  z = (y-mu)/(sigma)
  z <- (y - mu) / sigma
  E1 = exp(z)*(exp(z) + 2)
  E2 = (exp(-(3*mu)/sigma) + 2)
  E3 = exp(-exp(z))
  E4 = exp((y-3*mu)/sigma)
  E5 = (exp(-mu/sigma) + exp((2*y)/sigma))
  g  = (E4*E5*E3)/(sigma*E2)
  G  =  1 - (1 + E1/E2)*E3
  pdf = c*g*G^(c-1)
  sf = 1 - G^c
  lv<-censur*(log(pdf))+(1-censur)*(log(sf))
  sum(-lv)
}
valorin<-c(0.2070155,  0.3971063,  4.4367155, -0.0180685, -0.2439481)
LEPI<-optim(valorin,EPI,method="BFGS",hessian=T);
LEPI
n=nrow(dados)
criterios(LEPI$value,length(LEPI$par),n)
parametros1=LEPI$par
hessiana1=LEPI$hessian
IC(parametros1,hessiana1,n)

# Log-power Ishita 

PI<-function(par){
  c     = 1
  sigma = par[1]
  b0    = par[2]
  b1    = par[3]
  b2    = par[4]
  if(any(sigma < 1e-20)) return(.Machine$double.xmax^.5)
  mu=b0 + b1*dados$age + b2*dados$diab
  z = (y-mu)/(sigma)
  z <- (y - mu) / sigma
  E1 = exp(z)*(exp(z) + 2)
  E2 = (exp(-(3*mu)/sigma) + 2)
  E3 = exp(-exp(z))
  E4 = exp((y-3*mu)/sigma)
  E5 = (exp(-mu/sigma) + exp((2*y)/sigma))
  g  = (E4*E5*E3)/(sigma*E2)
  G  =  1 - (1 + E1/E2)*E3
  pdf = c*g*G^(c-1)
  sf = 1 - G^c
  lv<-censur*(log(pdf))+(1-censur)*(log(sf))
  sum(-lv)
}
valorin2<-c(1.19264269,  3.24014932, -0.01972019, -0.28483929)
LPI<-optim(valorin2,PI,method="BFGS",hessian=T);
LPI
n=nrow(dados)
criterios(LPI$value,length(LPI$par),n)
parametros2=LPI$par
hessiana2=LPI$hessian
IC(parametros2,hessiana2,n)

# Log-exponentiated WEibull

WE<-function(par){
  a     = par[1]
  sigma = par[2]
  b0    = par[3]
  b1    = par[4]
  b2    = par[5]
  if(any(sigma < 1e-20)) return(.Machine$double.xmax^.5)
  mu=b0 + b1*dados$age + b2*dados$diab
  z = (y-mu)/(sigma)
  f = (a/sigma)*exp(z)*exp(-exp(z))*(1 - exp(-exp(z)))^(a-1)
  h = 1-(1-exp(-exp(z)))^(a)
  lv = censur*(log(f))+(1-censur)*(log(h))
  sum(-lv)
}
valorin4<-c(0.88775507,  0.51063213,  4.55183901, -0.01822759, -0.28031389)
LWE<-optim(valorin4,WE,method="BFGS",hessian=T);
LWE
n=nrow(dados)
criterios(LWE$value,length(LWE$par),n)
parametros4=LWE$par
hessiana4=LWE$hessian
IC(parametros4,hessiana4,n)

# Log-exponentiated Frechét
EF<-function(par){
  c     = par[1]
  sigma = par[2]
  b0    = par[3]
  b1    = par[4]
  b2    = par[5]
  if(any(sigma < 1e-20)) return(.Machine$double.xmax^.5)
  mu=b0 + b1*dados$age + b2*dados$diab
  z = (y-mu)/(sigma)
  f = (c/sigma)*exp(-z)*(1 - exp(-exp(-z)))^(c-1)*exp(-exp(-z))
  h = (1 - exp(-exp(-z)))^c
  lv = censur*(log(f))+(1-censur)*(log(h))
  sum(-lv)
}
valorin6<-c(154.17951578,  3.81460618,  10.97235546,  -0.02122969, -0.30145028)
LEF<-optim(valorin6,EF,method="BFGS",hessian=T);
LEF
n=nrow(dados)
criterios(LEF$value,length(LEF$par),n)
parametros6=LEF$par
hessiana6=LEF$hessian
IC(parametros6,hessiana6,n)

# quantile residuals

FEPI<-function(par,y){
  c     = par[1]
  sigma = par[2]
  b0    = par[3]
  b1    = par[4]
  b2    = par[5]
  if(any(sigma < 1e-20)) return(.Machine$double.xmax^.5)
  mu=b0 + b1*dados$age + b2*dados$asthma
  z = (y-mu)/(sigma)
  v = (sigma*z + mu - 3*mu)/sigma
  v1 = (2*(sigma*z+mu))/sigma
  z1= ((c*exp(v))/(sigma*(exp(-(3*mu)/sigma) + 2)))
  z2 = (exp(-mu/sigma) + exp(v1))
  z3 = exp(-exp(z))
  z4 = (exp(z)*(exp(z)+2))/(exp(-(3*mu/sigma)) + 2)
  Ft = (1 - (1 + z4)*z3)^(c)
  return(Ft)
}

# Index plot

plot(qnorm(FEPI(LEPI$par,y)),pch=16,ylab = "Quantile residuals",xlab = "Index")
abline(h = c(-3,3), lty=2)

# Normal probability plot

q = rnorm(322)
qqplot(q,qnorm(FEPI(LEPI$par, y)), ylab="Sample Quantiles",
       xlab = "Theoretical Quantiles", pch=16)
qqline((qnorm(FEPI(LEPI$par, y))),lwd = 2)
